{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48485d3a-2007-4c8e-9e97-a8bb0b3edb04",
   "metadata": {},
   "source": [
    "Pre-req:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e5c148-ad66-4e2b-a43d-6719347050cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import datetime\n",
    "import pickle\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark\n",
    "\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307bbc78-b548-4a44-84d1-df89a7562f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/Galeforse/DST-Assessment-05/main/Data/NCSC%20Reports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22ebe9c0-6475-4b37-b550-d16c3349bc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:(221, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Article</th>\n",
       "      <th>topics</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23rd April 2021</td>\n",
       "      <td>['The NCSC is aware that a malicious piece of ...</td>\n",
       "      <td>['Cyber attack', 'Cyber strategy', 'Education'...</td>\n",
       "      <td>https://www.ncsc.gov.uk/report/weekly-threat-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16th April 2021</td>\n",
       "      <td>['Cyber security researchers have uncovered a ...</td>\n",
       "      <td>['Cyber strategy', 'Patching', 'Vulnerabilities']</td>\n",
       "      <td>https://www.ncsc.gov.uk/report/weekly-threat-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12th April 2021</td>\n",
       "      <td>['Cyber security researchers, Esentire, have w...</td>\n",
       "      <td>['Phishing', 'Social media', 'Personal data', ...</td>\n",
       "      <td>https://www.ncsc.gov.uk/report/weekly-threat-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2nd April 2021</td>\n",
       "      <td>['The UK education sector continues to face an...</td>\n",
       "      <td>['Education', 'Incident management', 'Secure d...</td>\n",
       "      <td>https://www.ncsc.gov.uk/report/weekly-threat-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>26th March 2021</td>\n",
       "      <td>['Earlier this month Microsoft confirmed that ...</td>\n",
       "      <td>['Cyber attack', 'Education', 'Mitigation', 'P...</td>\n",
       "      <td>https://www.ncsc.gov.uk/report/weekly-threat-r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            Title  \\\n",
       "0           0  23rd April 2021   \n",
       "1           1  16th April 2021   \n",
       "2           2  12th April 2021   \n",
       "3           3   2nd April 2021   \n",
       "4           4  26th March 2021   \n",
       "\n",
       "                                             Article  \\\n",
       "0  ['The NCSC is aware that a malicious piece of ...   \n",
       "1  ['Cyber security researchers have uncovered a ...   \n",
       "2  ['Cyber security researchers, Esentire, have w...   \n",
       "3  ['The UK education sector continues to face an...   \n",
       "4  ['Earlier this month Microsoft confirmed that ...   \n",
       "\n",
       "                                              topics  \\\n",
       "0  ['Cyber attack', 'Cyber strategy', 'Education'...   \n",
       "1  ['Cyber strategy', 'Patching', 'Vulnerabilities']   \n",
       "2  ['Phishing', 'Social media', 'Personal data', ...   \n",
       "3  ['Education', 'Incident management', 'Secure d...   \n",
       "4  ['Cyber attack', 'Education', 'Mitigation', 'P...   \n",
       "\n",
       "                                               Links  \n",
       "0  https://www.ncsc.gov.uk/report/weekly-threat-r...  \n",
       "1  https://www.ncsc.gov.uk/report/weekly-threat-r...  \n",
       "2  https://www.ncsc.gov.uk/report/weekly-threat-r...  \n",
       "3  https://www.ncsc.gov.uk/report/weekly-threat-r...  \n",
       "4  https://www.ncsc.gov.uk/report/weekly-threat-r...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"shape:\"+str(np.shape(df)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a530091-3c8f-40ed-a905-185a30625901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['The government has issued a cyber security alert to charities warning them of a spike in the number of criminals trying to access and change the private information of staff.\\\\nThe Charity Commission has received several reports from charities that have been targeted by fraudsters impersonating HR staff members, specifically attempting to change employees bank details. In all cases, the request was made through an email.\\\\nCharities should look out for email requests from spoofed or similar email addresses to their legitimate HR departments, finance departments or staff with authority to change bank details. The NCSC has provided guidance which can help with this.\\\\nLike most businesses, charities are increasingly reliant on computer technology and are at risk of falling victim to cyber criminals. The NCSC has published guidance on how to improve cyber security within a charity with the collection including specific phishing advice.', 'With Christmas shopping well underway, this week consumer association Which? revealed it had found “serious security flaws” in some children’s smart toys.\\\\nWorking with cyber security specialists, Which? raised concerns about some connected toys sold by major retailers, claiming that they lacked basic cyber security measures and were vulnerable to attack.\\\\n\\\\nThis investigation highlights the importance for manufacturers of internet connected devices to take every measure to ensure their products are safe to use.\\\\nEarlier this year the NCSC supported a DCMS consultation on regulatory proposals for consumer Internet of Things, which would create a minimum baseline for security requirements in smart devices.\\\\nWhich? has outlined five tips to help when buying and using smart toys:\\\\nRead the description of the connected toy carefully in the shop or online. Find out what the toy actually does and how your child will interact with it.\\\\nSearch online to see if there have been any security concerns raised about the toy previously, such as a leak of personal data. If you are at all concerned, consider a non-smart toy instead.\\\\nIf you do buy a smart toy, submit only the minimal amount of personal data required when setting up an account for your child. So, not too much data is exposed if things do go wrong. Do set strong passwords, though, to ensure any accounts are properly protected.\\\\nKeep an eye on your child when they’re playing with the smart toy, particularly if it can send or receive messages.\\\\nWhen your child is not playing with the smart toy, make sure you turn it off completely.\\\\nNCSC guidance on how to secure internet connected devices in the home is available.']\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[67,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f496b1fc-1c9d-4b0c-824d-b73eb5f33c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Cyber threat']\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[67,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8922142-643f-4869-b8fc-92afa45c1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3192c870-ea56-4277-90d7-3df25a1f75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d246cf25-67ca-454f-a58e-f1a2367940fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Gabriel-PC.Home:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Python Spark SQL basic example</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d459cb02e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d327aaa-043a-4c7c-bc1e-c874929cda43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ede8b0bf-1dfc-4ef9-ae3d-27e2864d4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = spark.read.load(\"NCSC Reports.csv\",format='csv', header = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6a3145d-b94e-4801-909c-8c6795c14273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a5c2b44-5f6d-4545-a3a9-27dd3d668e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- Unnamed: 0: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Article: string (nullable = true)\n",
      " |-- topics: string (nullable = true)\n",
      " |-- Links: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "067ef991-e56c-449a-af41-1c3577799ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = spark.read.load(\"Data/NCSC Reports.csv\",\n",
    "#                     format=\"csv\", sep=\";\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "744e8685-4c7c-40ea-b4fd-7fdb63576259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3 = pickle.load(open('wordlist.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce374470-ea93-4830-a241-098576220e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce47b905-2c26-4c11-935e-2c27a09ac65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import (Tokenizer, Normalizer,\n",
    "                                Lemmatizer, LemmatizerModel, StopWordsCleaner)\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10140b0e-4fc1-4f0b-bacf-f7217b463511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d176dcf6-faed-440b-93a7-d0487f9cf51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = stopwords.words('english')\n",
    "eng_words = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2318b7e1-a5c4-4a32-95d6-dc510395468e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'JavaPackage' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-9addc3d75d81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdocumentAssembler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDocumentAssembler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m      \u001b[1;33m.\u001b[0m\u001b[0msetInputCol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Article'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m      \u001b[1;33m.\u001b[0m\u001b[0msetOutputCol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Articles'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programs\\Anaconda\\envs\\Spark\\lib\\site-packages\\sparknlp\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mkeyword_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDocumentAssembler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"com.johnsnowlabs.nlp.DocumentAssembler\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setDefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"document\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcleanupMode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'disabled'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Programs\\Anaconda\\envs\\Spark\\lib\\site-packages\\sparknlp\\internal.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, classname)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_class_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_java_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[1;34m(java_class, *args)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mjava_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'JavaPackage' object is not callable"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "     .setInputCol('Article') \\\n",
    "     .setOutputCol('Articles')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "     .setInputCols(['Articles']) \\\n",
    "     .setOutputCol('token')\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "     .setInputCols(['token']) \\\n",
    "     .setOutputCol('normalized') \\\n",
    "     .setLowercase(True)\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "     .setInputCols(['normalized']) \\\n",
    "     .setOutputCol('clean_lemma') \\\n",
    "     .setCaseSensitive(False) \\\n",
    "     .setStopWords(eng_stopwords)\n",
    "\n",
    "finisher = Finisher() \\\n",
    "     .setInputCols(['clean_lemma']) \\\n",
    "     .setCleanAnnotations(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
