{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef8f7c5-fe43-42af-8dec-c7411bf22d6e",
   "metadata": {},
   "source": [
    "## Attempted implementation of the Spark mllib package\n",
    "\n",
    "Following the example from [the documentation](https://spark.apache.org/docs/latest/ml-clustering.html) using our data generated in [this file](https://github.com/Galeforse/DST-Assessment-05/blob/main/Gabriel%20Grant/rdd%20lda%20test.ipynb).\n",
    "\n",
    "We tried to form data that was similar to that used in examples using the following packages, however due to a lack of understanding of the intricacies of how the package worked and an overall lack of documentation, with only very simple examples. Therefore while we could convert our data to be used by this package after many failed attempts at trying to get something working and extensive web research of the problem, we still ended up not finding any particularly useful results.\n",
    "\n",
    "It was hard to implement this on our data without a wide variety of examples to cross reference with. I managed to convert the data to look like the data found in the examples however, in doing so the data seemed to lose meaning and also didn't seem to use any form of dictionary and therefore the topics seemed to be practically random with no relevance between any of the top terms.\n",
    "\n",
    "The previously linked file also contains attempts at another similar implementation of LDA using data formatted as RDDs, however once again converting our data from the very familiar Pandas dataframe to the far more confusing and unknown spark.DataFrame format. However this package would not work with data unless it was in the correct format that it wanted for processing. I tried re-running the pipeline that was used in a previous part of the report to filter and lemmatize the data and see if this process would allow us more suitable results however the amount of investment required to get this to work weighed up against the fact we had already managed to get SparkNLP running both well, and doing a very similar job to what we would be attempting here it didn't seem worth persuing this any further with the time we had available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79577d83-b583-4f97-b9f1-44d9c9a67c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.sql import SparkSession\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891bf20-53b9-4454-b96c-a57e90ada130",
   "metadata": {},
   "source": [
    "Here we create a SparkSession; in a confusing twist it seems that certain spark packages only work when a certain type of spark instance is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e2b19a-2649-4a02-9369-e5d90a417fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"LDAExample\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6912d857-ef6d-481d-8425-e2c5be111117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf33616-e5bb-4263-8006-480ce6a201ec",
   "metadata": {},
   "source": [
    "As we see above this is listed as `pyspark.sql.session.SparkSession` this is different from the Spark we ran in the workshop which worked off of SparkContext, however they seem to be quite similar in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "698a1055-9589-45a9-88da-18b43d766500",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.read.format(\"libsvm\").load(\"list_5.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a78463-9f12-496f-9859-c99e6d10e3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5073561999999985\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "lda = LDA(k=10, maxIter=10)\n",
    "model = lda.fit(dataset)\n",
    "end=timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b62ee9ca-93f2-435b-9eee-a58aa1266dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -345816.93348027\n",
      "The upper bound on perplexity: 7.8734332106978275\n"
     ]
    }
   ],
   "source": [
    "ll = model.logLikelihood(dataset)\n",
    "lp = model.logPerplexity(dataset)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0b0512-93df-4003-9bbf-b167fffe0c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+------------------+---------------------------------------------------------------------+\n",
      "|topic|termIndices       |termWeights                                                          |\n",
      "+-----+------------------+---------------------------------------------------------------------+\n",
      "|0    |[2, 3, 0]         |[2.1220105465170717E-4, 2.0555473265004118E-4, 1.9335447291411753E-4]|\n",
      "|1    |[2556, 7049, 3276]|[1.7550251272777155E-4, 1.753752814376797E-4, 1.7440217125461052E-4] |\n",
      "|2    |[299, 237, 474]   |[2.806766970068444E-4, 2.451525197585433E-4, 2.33487290749287E-4]    |\n",
      "|3    |[125, 101, 116]   |[4.88522444078734E-4, 4.7991674529694676E-4, 3.8305296586093734E-4]  |\n",
      "|4    |[299, 237, 474]   |[3.995415062855056E-4, 3.4246963533755864E-4, 3.221562049409293E-4]  |\n",
      "|5    |[1906, 2718, 1200]|[1.7357597850758746E-4, 1.701536244093257E-4, 1.694338983731133E-4]  |\n",
      "|6    |[0, 1, 7]         |[0.005858437384179291, 0.004798537356599913, 0.004138344897170852]   |\n",
      "|7    |[7634, 3340, 2338]|[1.8257875231772E-4, 1.7801922562497545E-4, 1.7240357994150723E-4]   |\n",
      "|8    |[299, 97, 2]      |[3.346066506177313E-4, 2.943280860510282E-4, 2.9054635549082756E-4]  |\n",
      "|9    |[4346, 1278, 5202]|[1.7543472117552628E-4, 1.7518038114197113E-4, 1.7331662142119715E-4]|\n",
      "+-----+------------------+---------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = model.describeTopics(3)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a510f429-76f8-4a41-aaff-b0ae60fdac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from urllib.request import urlopen\n",
    "\n",
    "x = urlopen(\"https://github.com/Galeforse/DST-Assessment-05/raw/main/Data/Report_counts_dict.p\")\n",
    "counts = pickle.load(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b984e2c-5b7a-4e30-b9a3-db46cc7fe130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spyware pcs ncsc\n"
     ]
    }
   ],
   "source": [
    "k=list(counts[\"23rd April 2021\"].keys())\n",
    "print(k[2]+str(\" \")+k[3]+str(\" \")+k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3e18fee-cc0b-4e48-8eac-5ea653fcab19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enterprises cyberscoop desire\n"
     ]
    }
   ],
   "source": [
    "print(k[2556]+str(\" \")+k[7049]+str(\" \")+k[3276])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a22d80c2-24bf-427f-a07b-bad52e918e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recklessly harnessing discreet\n"
     ]
    }
   ],
   "source": [
    "print(k[299]+str(\" \")+k[237]+str(\" \")+k[474])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c98c96-db2a-4283-90ad-16f26b501b82",
   "metadata": {},
   "source": [
    "I'm confused as to how this package exactly works, it doesn't seem to learn LDA in a typical way; there is no use of dictionaries and therefore the topic clustering seems to be random and therefore not particularly interesting to draw conclusions from. This is mostly due to the fact we had to convert the data to vectorised counts to be used with the package; the package would not work with strings, constantly throwing errors, however without a link to the strings they represent it makes sense that there is no cohesion amongst the results. The examples used purely numerical data and when searching for further examples that used text, it was hard to find examples in Python, and most Python examples instead reccomended the use of the SparkNLP package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43cc679f-f0c8-4ceb-814d-f70df4ef8f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.224187699999998\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "lda = LDA(k=8, maxIter=200,optimizer=\"online\")\n",
    "model = lda.fit(dataset)\n",
    "end=timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "892c25fd-3dae-4e2e-9e7d-d12ff9b7e912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+------------------+---------------------------------------------------------------------+\n",
      "|topic|termIndices       |termWeights                                                          |\n",
      "+-----+------------------+---------------------------------------------------------------------+\n",
      "|0    |[2, 3, 0]         |[1.2995505950716996E-4, 1.2976493016961992E-4, 1.2941609796973176E-4]|\n",
      "|1    |[2556, 7049, 3276]|[1.2890833247771697E-4, 1.2890468914848928E-4, 1.288768236700432E-4] |\n",
      "|2    |[299, 237, 474]   |[1.3462094242388926E-4, 1.324381390790369E-4, 1.3165791137095166E-4] |\n",
      "|3    |[125, 101, 2]     |[1.399312753735091E-4, 1.3858388877681222E-4, 1.376339746352359E-4]  |\n",
      "|4    |[299, 237, 474]   |[1.3623260160529753E-4, 1.338991027413662E-4, 1.3309318220729968E-4] |\n",
      "|5    |[1906, 2718, 1200]|[1.2885053889353682E-4, 1.2875273335901836E-4, 1.2873216471309296E-4]|\n",
      "|6    |[0, 1, 2]         |[0.00966607396047121, 0.0075833849721201755, 0.006542041077760093]   |\n",
      "|7    |[7634, 3340, 2338]|[1.2910984313651487E-4, 1.289793717404958E-4, 1.288186793745455E-4]  |\n",
      "+-----+------------------+---------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = model.describeTopics(3)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "301de73c-5238-4bc8-a011-69906bb5062d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployednfurther defense batik\n"
     ]
    }
   ],
   "source": [
    "print(k[1906]+str(\" \")+k[2718]+str(\" \")+k[1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df597683-db6f-4af6-8217-4151e1da1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a0f64-77b8-445d-b1c5-dcbc5824d275",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[Spark Documentation](https://spark.apache.org/docs/latest/ml-clustering.html)\n",
    "\n",
    "[Further Spark Documentation (RDD)](https://spark.apache.org/docs/latest/mllib-clustering.html)\n",
    "\n",
    "[Official Spark GitHub Repo - contains many examples](https://github.com/apache/spark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
